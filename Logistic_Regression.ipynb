{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gjduart/Machine-Learning/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oaY368logPS"
      },
      "source": [
        "<h5>Student: Gabriel Jonas da Silva Duarte</h5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp0gU-uXogPT"
      },
      "source": [
        "### Exercice of Machine Learning - IFCE - 2020.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VRAmoYqogPT"
      },
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiWVg3iKogPW"
      },
      "source": [
        "<h3>Loading and filtering the dataset</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEn0ddvDogPX"
      },
      "source": [
        "for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QPn7zRpogPX"
      },
      "source": [
        "# Loading and Filtering the dataset for training\n",
        "train_dataset = datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
        "idx = (train_dataset.targets==1) | (train_dataset.targets==3)\n",
        "train_dataset.targets = train_dataset.targets[idx]\n",
        "train_dataset.data = train_dataset.data[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUS1kvcLogPZ"
      },
      "source": [
        "to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7waZwwAzogPa",
        "outputId": "83cafb20-a8a5-4419-d816-7ec8940e3550"
      },
      "source": [
        "# Loading and Filtering the dataset for test\n",
        "test_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\n",
        "indx = (test_dataset.targets==1) | (test_dataset.targets==3)\n",
        "test_dataset.targets = test_dataset.targets[indx]\n",
        "test_dataset.data = test_dataset.data[indx]\n",
        "test_dataset.data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2145, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "594boTmOogPd"
      },
      "source": [
        "<h4>Treating data set and define new labels for the selected numbers</h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YIq4oQcogPd",
        "outputId": "f1d11ed2-3ceb-4771-9c14-449465079ad5"
      },
      "source": [
        "n_training_samples = train_dataset.data.shape[0]\n",
        "learning_rate = 1e-4 #Setting the learning rate\n",
        "\n",
        "\n",
        "train_data = train_dataset.data.view(n_training_samples, -1) #Arranging in 28x28 vectors\n",
        "train_targets = train_dataset.targets.view(n_training_samples, -1)\n",
        "y_train = train_targets.float()\n",
        "x_train = train_data.float()\n",
        "\n",
        "\n",
        "\n",
        "y_train[y_train==1] = -1\n",
        "y_train[y_train==3] = 1\n",
        "\n",
        "\n",
        "\n",
        "n_test_samples = test_dataset.data.shape[0]\n",
        "test_data = test_dataset.data.view(n_test_samples, -1)\n",
        "test_targets = test_dataset.targets.view(n_test_samples, -1)\n",
        "\n",
        "y_test = test_targets.float()\n",
        "x_test = test_data.float()\n",
        "\n",
        "y_test[y_test==1] = -1\n",
        "y_test[y_test==3] = 1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Test data:', x_test.shape)\n",
        "print('Img class:', y_test[3].item())\n",
        "img = test_data[3].view(28, 28)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data: torch.Size([2145, 784])\n",
            "Img class: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOe0lEQVR4nO3dcYxV5ZnH8d8jgkbBhCkRBjBrIZjshqjdoG6QrNWmDUIU+0cNmDSsSKYJNcFk40q6JlU3RnC3u/6hIQ7ppLipVBJFTG0EJER2gzYMBJEpC7qGLZSRiZJYGhIr8Owfc9gdcM57h3POvec6z/eTTO7c88y558nFn+fc+55zXnN3ARj9Lqu7AQCtQdiBIAg7EARhB4Ig7EAQl7dyY2bGV/9Ak7m7Dbe81J7dzOab2SEz+8jMVpV5LQDNZUXH2c1sjKTDkr4r6Zik3ZKWuPvvEuuwZwearBl79lslfeTuH7v7nyX9StKiEq8HoInKhH2apKNDnh/Lll3AzLrMrNfMektsC0BJZb6gG+5Q4SuH6e7eLalb4jAeqFOZPfsxSdcNeT5d0vFy7QBoljJh3y1plpl908zGSVos6Y1q2gJQtcKH8e5+xswelrRF0hhJPe7eV1lnACpVeOit0Mb4zA40XVNOqgHw9UHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBAtnbL562z8+PG5tenTpyfXXbFiRalt9/T0JOv79u0r9fqIgT07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgTBLK6Z1Di6JD366KO5tccff7zqdi5w9uzZZP2VV17Jra1cuTK57smTJwv1hPaVN4trqZNqzOyIpFOSzko64+5zyrwegOap4gy6O9390wpeB0AT8ZkdCKJs2F3SVjPbY2Zdw/2BmXWZWa+Z9ZbcFoASyh7G3+7ux83sWknbzOy/3H3n0D9w925J3VJ7f0EHjHal9uzufjx7HJC0SdKtVTQFoHqFw25mV5vZhPO/S/qepANVNQagWoXH2c1shgb35tLgx4GX3f3pBuu07WH8008nW9eqVata1Em1Pvnkk2T9wQcfTNa3bt1aZTtogcrH2d39Y0k3Fe4IQEsx9AYEQdiBIAg7EARhB4Ig7EAQ3Eo6c+TIkcLrNhq+fOGFF5L1vr6+ZH3s2LHJ+lNPPZVbmzJlSnLdzZs3J+tr1qxJ1p999tlk/fTp08k6Woc9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4Ewa2kM2+++WayPn/+/Nzaxo0bk+suWbKkUE8jNW/evNzapk2bcmuS1NHRUWrbL7/8crK+bNmy3NqXX35ZatsYXt4lruzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtkzjd6Hc+fO5dZuvPHG5LqNrldvprlz5ybrzzzzTLKeGsMfidQ4fKPbWJ85c6bUtqNinB0IjrADQRB2IAjCDgRB2IEgCDsQBGEHgmCcPbNt27Zk/a677sqtzZw5M7lumXvSN9ttt92WrDe6zn/ixImFt93oOv9G9wnA8AqPs5tZj5kNmNmBIcs6zGybmX2YPRb/FwfQEiM5jP+FpItv07JK0nZ3nyVpe/YcQBtrGHZ33ynp5EWLF0lan/2+XtJ9FfcFoGJF53qb7O79kuTu/WZ2bd4fmlmXpK6C2wFQkaZP7Oju3ZK6pfb+gg4Y7YoOvZ0ws05Jyh4HqmsJQDMUDfsbkpZmvy+VlJ73F0DtGh7Gm9kGSd+WNMnMjkn6qaTVkjaa2UOSfi/pB81sshUOHjyYrKfG2ctavnx5sv7AAw8k6y+++GKV7Vxgw4YNyfqKFSsKv/asWbMKr4tL1zDs7p535sN3Ku4FQBNxuiwQBGEHgiDsQBCEHQiCsANBNP0Muq+L3t7ewus2upX0lVdemaw///zzyfrYsWOT9TvuuCNZb1eNhhwPHTqUrDe6LPnzzz+/5J5GM/bsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEt5LOXHPNNcn6vffem1t7/fXXk+tOnjw5Wd+zZ0+yPmHChGQ9qtOnTyfrXV35d0PbvDl9C4ZGr93OmLIZCI6wA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0NLFy4MFm///77k/WOjo7c2oIFCwr1NNodOHAgWW90++6+vr4q26kU4+xAcIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7KPAmDFjcmtlr4VvdC1+o/9+BgYGCm/7ySefTNaXLVuWrF911VWFt/32228n64899liyvm/fvsLbLqvwOLuZ9ZjZgJkdGLLsCTP7g5nty344cwNocyM5jP+FpPnDLP83d785+/lNtW0BqFrDsLv7TkknW9ALgCYq8wXdw2a2PzvMn5j3R2bWZWa9ZlZ8MjUApRUN+1pJMyXdLKlf0s/y/tDdu919jrvPKbgtABUoFHZ3P+HuZ939nKR1km6tti0AVSsUdjPrHPL0+5LS1wsCqF3DcXYz2yDp25ImSToh6afZ85sluaQjkn7k7v0NN8Y4+7AmTZqUrN9www3J+q5du6ps52tj7ty5yfratWtza7Nnzy617a1btybrd999d6nXLyNvnP3yEay4ZJjFPy/dEYCW4nRZIAjCDgRB2IEgCDsQBGEHguAS1xa45557kvXnnnsuWZ86dWqyvnjx4txao6mJR7PU5b179+5Nrjtjxoxk/dSpU8l66t9Ekt56661kvQxuJQ0ER9iBIAg7EARhB4Ig7EAQhB0IgrADQTDO3gJLlgx34eD/6+npSdbHjRuXrKf+DefNm5dc97333kvWR6s5c9I3Tnr33XeT9csuS+8nd+7cmazfeeedyXoZjLMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBAN7y6L8jZs2JCsT5s2LVlfs2ZNsm427LCqpPR0zpHddNNNyXrqPR2J/fv3l1q/GdizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLO3ge7u7mR9/vz5yXrq2uiXXnopue4777yTrK9evTpZP3z4cLLeTCtXrkzWly9fnlubOXNmct2y4+ztqOGe3cyuM7MdZnbQzPrMbGW2vMPMtpnZh9njxOa3C6CokRzGn5H09+7+l5L+RtKPzeyvJK2StN3dZ0nanj0H0KYaht3d+919b/b7KUkHJU2TtEjS+uzP1ku6r1lNAijvkj6zm9n1kr4l6beSJrt7vzT4PwQzuzZnnS5JXeXaBFDWiMNuZuMlvSrpEXf/40i/wHD3bknd2WuEvOEk0A5GNPRmZmM1GPRfuvtr2eITZtaZ1TslDTSnRQBVaHgraRvcha+XdNLdHxmy/J8lfebuq81slaQOd/+HBq/Fnr2A8ePHJ+vvv/9+bq2zszO57hVXXJGsnzt3rlS9mS6/vL6R4927dyfrCxcuTNY/++yzKtu5QN6tpEfybt0u6YeSPjCzfdmyn0haLWmjmT0k6feSflBFowCao2HY3f0/JeV9QP9Ote0AaBZOlwWCIOxAEIQdCIKwA0EQdiAIpmwe5ZYuXZqsL168OFmfPXt2sj516tRL7qkd7Nq1K1nfsmVLsr5u3bpk/cSJE5fcU1WYshkIjrADQRB2IAjCDgRB2IEgCDsQBGEHgmCcHUlTpkxJ1htda9/VlX9Hsh07diTXveWWW5L1Rrex7u3tza0dPXo0ue4XX3yRrLczxtmB4Ag7EARhB4Ig7EAQhB0IgrADQRB2IAjG2YFRhnF2IDjCDgRB2IEgCDsQBGEHgiDsQBCEHQiiYdjN7Doz22FmB82sz8xWZsufMLM/mNm+7GdB89sFUFTDk2rMrFNSp7vvNbMJkvZIuk/S/ZL+5O7/MuKNcVIN0HR5J9WMZH72fkn92e+nzOygpGnVtgeg2S7pM7uZXS/pW5J+my162Mz2m1mPmU3MWafLzHrNLP8eQQCabsTnxpvZeEnvSHra3V8zs8mSPpXkkv5Jg4f6yxq8BofxQJPlHcaPKOxmNlbSryVtcfd/HaZ+vaRfu3tyFkDCDjRf4QthzMwk/VzSwaFBz764O+/7kg6UbRJA84zk2/h5kv5D0geSzmWLfyJpiaSbNXgYf0TSj7Iv81KvxZ4daLJSh/FVIexA83E9OxAcYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IIiGN5ys2KeS/mfI80nZsnbUrr21a18SvRVVZW9/kVdo6fXsX9m4Wa+7z6mtgYR27a1d+5LorahW9cZhPBAEYQeCqDvs3TVvP6Vde2vXviR6K6olvdX6mR1A69S9ZwfQIoQdCKKWsJvZfDM7ZGYfmdmqOnrIY2ZHzOyDbBrqWueny+bQGzCzA0OWdZjZNjP7MHscdo69mnpri2m8E9OM1/re1T39ecs/s5vZGEmHJX1X0jFJuyUtcffftbSRHGZ2RNIcd6/9BAwz+1tJf5L00vmptczsWUkn3X119j/Kie7+WJv09oQucRrvJvWWN83436nG967K6c+LqGPPfqukj9z9Y3f/s6RfSVpUQx9tz913Sjp50eJFktZnv6/X4H8sLZfTW1tw935335v9fkrS+WnGa33vEn21RB1hnybp6JDnx9Re8727pK1mtsfMuupuZhiTz0+zlT1eW3M/F2s4jXcrXTTNeNu8d0WmPy+rjrAPNzVNO43/3e7ufy3pbkk/zg5XMTJrJc3U4ByA/ZJ+Vmcz2TTjr0p6xN3/WGcvQw3TV0vetzrCfkzSdUOeT5d0vIY+huXux7PHAUmbNPixo52cOD+DbvY4UHM//8fdT7j7WXc/J2mdanzvsmnGX5X0S3d/LVtc+3s3XF+tet/qCPtuSbPM7JtmNk7SYklv1NDHV5jZ1dkXJzKzqyV9T+03FfUbkpZmvy+VtLnGXi7QLtN4500zrprfu9qnP3f3lv9IWqDBb+T/W9I/1tFDTl8zJL2f/fTV3ZukDRo8rPtSg0dED0n6hqTtkj7MHjvaqLd/1+DU3vs1GKzOmnqbp8GPhvsl7ct+FtT93iX6asn7xumyQBCcQQcEQdiBIAg7EARhB4Ig7EAQhB0IgrADQfwvSLGpxyVeuXgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOUBFMGlogPg"
      },
      "source": [
        "$$h(\\vec x) = logistic(\\vec x^T \\vec \\theta)\\\\\n",
        "            = \\frac{1}{1+e^{\\vec -x^T \\vec \\theta}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_6Gls1RogPg"
      },
      "source": [
        "ou seja $$P(y= +1/ \\vec x) = h(\\vec x) \\\\\n",
        "           p(y = -1 / \\vec x) = 1-h(\\vec x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xa3l465ogPg"
      },
      "source": [
        "<h3>O treinamento se dará através do maximum likelihood(Principio da máxima verossimilhança)</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yvdvoIOogPh"
      },
      "source": [
        "$$\\hat{\\vec \\theta}_{ML} = argmax \\prod_{n=1}^{N} P_{\\vec \\theta}(Y_n / \\vec X_n)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKdypdlGogPh"
      },
      "source": [
        "$$= argmax \\sum_{n=1}^{N} log\\ P_{\\vec \\theta}(Y_n/\\vec X_n)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpTY3zWcogPi"
      },
      "source": [
        "$$P_{\\vec \\theta} = \\left \\{ \\begin{matrix} logistic(\\vec x^T\\theta) & \\mbox{, }\\mbox{ y=1} \\\\ 1-logistic(\\vec x^T\\theta) & \\mbox{, }\\mbox{ y=-1} \\end{matrix} \\right.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJlmVkEIogPi"
      },
      "source": [
        "Podendo ser Reescrito como equação unica.$$\\\\\\boxed{P_{\\vec \\theta} = logistic(y\\vec x^T\\theta)} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NST4tI5IogPi"
      },
      "source": [
        "def train(x,y,n_epochs,learning_rate):\n",
        "    theta = torch.zeros(784,1)\n",
        "    for epoch in range(n_epochs):\n",
        "        denominator = 1 + torch.exp(y*(x @ theta))\n",
        "        numerator = y * x\n",
        "        gradient = -torch.mean(numerator/denominator,axis=0, keepdim=True).T\n",
        "        theta = theta - learning_rate* gradient\n",
        "    return theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCP9Mp2oogPl"
      },
      "source": [
        "theta = train(x_train,y_train,100,learning_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU0VelqUogPn",
        "outputId": "773f7946-c258-43fa-8ebb-a662a4789726"
      },
      "source": [
        "#y_hat = 1/(1+torch.exp(-x_test@theta))\n",
        "y_hat = torch.sigmoid(x_test@theta)\n",
        "\n",
        "y_hat[y_hat < 0.5] = -1\n",
        "y_hat[y_hat >= 0.5] = 1\n",
        "\n",
        "correto = 0\n",
        "\n",
        "for i in range(y_hat.shape[0]):\n",
        "    if(y_hat[i] == y_test[i]):\n",
        "        correto += 1\n",
        "accuracy = 100 * correto/y_hat.shape[0]\n",
        "accuracy\n",
        "print(\"Aproach:\", accuracy )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aproach: 99.44055944055944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mWk7PCXogPq"
      },
      "source": [
        "Para os pares a acurácia foi de aproximadamente: <br>\n",
        "(5,7) = 99,2% <br>\n",
        "(2,7) = 98%   <br>\n",
        "(1,2) = 99.2% <br>\n",
        "(1,3) = 99,4% <br>\n",
        "\n",
        "a melhor acurácia foi para os pares de digitos (1,3) e a pior foi para os pares(2,7)."
      ]
    }
  ]
}